{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1e1ccb-9d0c-42b5-8355-bc4522fba824",
   "metadata": {},
   "source": [
    "**Sections:**<a name=\"contents\"></a>\n",
    "\n",
    "[Control data download](#control_data_download)\n",
    "\n",
    "[Create symbolink link copies for all experimental fastq files](#symb_link_input)\n",
    "\n",
    "[Quality control](#QC_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33182800-a2e4-47c3-8c18-590b03541527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# general purpose packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats as smstats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import umap\n",
    "import rpy2\n",
    "\n",
    "from multiprocessing import Process, Manager, Pool\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('seaborn')\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['backend'] = \"Qt5Agg\"\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from adjustText import adjust_text\n",
    "import builtins\n",
    "%matplotlib inline\n",
    "\n",
    "# for normalization\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "# for working with yaml files\n",
    "import ruamel.yaml\n",
    "\n",
    "# for working with genomic intervals\n",
    "import pyranges as pr\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb77454-c2f4-4c14-aa4a-c37d6ab961da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvalue_star(pval, thr=0.05):\n",
    "    if thr == 0.05:\n",
    "        if pval < 0.001:\n",
    "            return \"***\"\n",
    "        elif pval < 0.01:\n",
    "            return \"**\"\n",
    "        elif pval < 0.05:\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"ns\"\n",
    "    elif thr == 0.1:\n",
    "        if pval < 0.001:\n",
    "            return \"***\"\n",
    "        elif pval < 0.01:\n",
    "            return \"**\"\n",
    "        elif pval < 0.1:\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"ns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c68b8f6-6004-4243-8dc3-5053639c85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths to subdirectories\n",
    "subdirs = {}\n",
    "\n",
    "subdirs['main_project_dir'] = '/scicore/home/zavolan/GROUP/RBP_perturbational_networks/'\n",
    "subdirs['wf_dir'] = '/scicore/home/zavolan/mirono0000/Projects/RBP_perturbational_networks/WF/'\n",
    "\n",
    "subdirs['human_annotation_dir'] = '/scicore/home/zavolan/GROUP/Genomes/homo_sapiens/'\n",
    "\n",
    "# shared project folder \n",
    "subdirs['shared_project_dir'] = subdirs['main_project_dir']\n",
    "subdirs['temp_dir'] = subdirs['shared_project_dir']+'temp_dir/'\n",
    "subdirs['slurm_dir'] = subdirs['temp_dir']+'slurm/'\n",
    "subdirs['scripts_dir'] = subdirs['shared_project_dir']+'scripts/'\n",
    "subdirs['figures_dir'] = subdirs['shared_project_dir']+'figures/'\n",
    "subdirs['fastq_dir'] = subdirs['shared_project_dir']+'input_fastq/'\n",
    "subdirs['metadata_dir'] = subdirs['shared_project_dir']+'metadata/'\n",
    "\n",
    "subdirs['wf_runs_dir'] = subdirs['shared_project_dir']+'wf_runs/'\n",
    "\n",
    "# paths to files\n",
    "file_paths = {}\n",
    "### genome annotation files\n",
    "file_paths['human_genome_file'] = subdirs['human_annotation_dir']+'GRCh38.primary_assembly.genome.fa'\n",
    "file_paths['human_annotation_file'] = subdirs['human_annotation_dir']+'hg38_v42/gencode.v42.annotation.gtf'\n",
    "file_paths['human_RNAcentral_annotation_file'] = subdirs['human_annotation_dir']+'hg38_v42/homo_sapiens.GRCh38.gff3.gz'\n",
    "file_paths['human_enriched_annotation_file'] = subdirs['human_annotation_dir']+'hg38_v42/enriched.gencode.v42.annotation.gtf'\n",
    "\n",
    "os.system('mkdir -p '+' '.join(list(subdirs.values()))) # create all subdirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4c3dc-5324-4ad9-8eb8-0cbacf05afde",
   "metadata": {},
   "source": [
    "# Make enriched gtf file for mouse and human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8b50f4-1edc-4957-b471-1b9748bd3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "organisms = ['human']\n",
    "\n",
    "for organism in organisms:\n",
    "    command = 'samtools faidx '+file_paths[organism+'_genome_file']\n",
    "    out = subprocess.check_output(command, shell=True)\n",
    "\n",
    "    gtf_df = pd.read_csv(file_paths[organism+'_annotation_file'],delimiter=\"\\t\",index_col=None,header=None,skiprows=5)\n",
    "\n",
    "    rna_central = pd.read_csv(file_paths[organism+'_RNAcentral_annotation_file'],delimiter=\"\\t\",index_col=None,header=None,skiprows=1,compression='gzip')\n",
    "    rna_central[2] = rna_central[2].str.replace('noncoding_exon','exon')\n",
    "    rna_central['gene_biotype'] = rna_central[8].str.split(';type=|;',expand=True)[1]\n",
    "    rna_central['gene_source'] = 'RNA_central'\n",
    "    rna_central['gene_id'] = rna_central[8].str.split('ID=|;|:',expand=True)[4]\n",
    "\n",
    "    rna_central_exons = rna_central.loc[rna_central[2]=='exon'].copy().reset_index(drop=True)\n",
    "    rna_central_exons['exon_id'] = rna_central_exons['gene_id']+'.transcript'+'.'+rna_central_exons[8].str.split('ID=|;|:',expand=True)[5]\n",
    "    rna_central_exons['exon_number'] = rna_central_exons[8].str.split('ID=|;|:',expand=True)[5].str.split('exon',expand=True).iloc[:, -1]\n",
    "    rna_central_exons[8] = 'gene_id \"'+rna_central_exons['gene_id']+'\"; transcript_id \"'+rna_central_exons['gene_id']+'.transcript'+'\"; exon_number \"'+rna_central_exons['exon_number']+'\"; gene_source \"'+rna_central_exons['gene_source']+'\"; gene_biotype \"'+rna_central_exons['gene_biotype']+'\"; transcript_source \"'+rna_central_exons['gene_source']+'\"; transcript_biotype \"'+rna_central_exons['gene_biotype']+'\"; exon_id \"'+rna_central_exons['exon_id']+'\"; tag \"'+rna_central['gene_source']+'\";'\n",
    "    rna_central_exons['order']=3\n",
    "\n",
    "    rna_central_exons['transcript_id'] = rna_central_exons['gene_id']+'.transcript'\n",
    "    rna_central_exons['exon_coords'] = rna_central_exons[3].astype('str')+'_'+rna_central_exons[4].astype('str')+','\n",
    "    rna_central_gr_transcripts = rna_central_exons.groupby([0,6,'transcript_id']).agg({'exon_coords':sum}).reset_index()\n",
    "    rna_central_gr_transcripts['transcript_alt_id'] = rna_central_gr_transcripts[0].astype('str')+'_'+rna_central_gr_transcripts[6]+'_'+rna_central_gr_transcripts['exon_coords']\n",
    "\n",
    "    gtf_df_exons = gtf_df.loc[gtf_df[2]=='exon'].reset_index(drop=True)\n",
    "    gtf_df_exons['transcript_id'] = gtf_df_exons[8].str.split('transcript_id \"',expand=True)[1].str.split('\"',expand=True)[0]\n",
    "    gtf_df_exons['exon_coords'] = gtf_df_exons[3].astype('str')+'_'+gtf_df_exons[4].astype('str')+','\n",
    "    gtf_df_gr_transcripts = gtf_df_exons.groupby([0,6,'transcript_id']).agg({'exon_coords':sum}).reset_index()\n",
    "    gtf_df_gr_transcripts['transcript_alt_id'] = gtf_df_gr_transcripts[0].astype('str')+'_'+gtf_df_gr_transcripts[6]+'_'+gtf_df_gr_transcripts['exon_coords']\n",
    "    ensembl_transcripts = list(gtf_df_gr_transcripts['transcript_alt_id'].unique())\n",
    "\n",
    "    preserve_transcripts_list = list(rna_central_gr_transcripts.loc[~rna_central_gr_transcripts['transcript_alt_id'].isin(ensembl_transcripts)]['transcript_id'].unique()) # when a transcript is present in ensemble and RNA central, prioritize ensemble\n",
    "    rna_central_exons = rna_central_exons.loc[rna_central_exons['transcript_id'].isin(preserve_transcripts_list)].reset_index(drop=True)\n",
    "    rna_central['transcript_id'] = rna_central['gene_id']+'.transcript'\n",
    "    rna_central = rna_central.loc[rna_central['transcript_id'].isin(preserve_transcripts_list)].reset_index(drop=True)\n",
    "\n",
    "    rna_central_exons = rna_central_exons[list(range(0,9))+['gene_id','order']]\n",
    "\n",
    "    rna_central_transcripts = rna_central.loc[rna_central[2]=='transcript'].copy().reset_index(drop=True)\n",
    "    rna_central_transcripts[8] = 'gene_id \"'+rna_central_transcripts['gene_id']+'\"; transcript_id \"'+rna_central_transcripts['gene_id']+'.transcript'+'\"; gene_source \"'+rna_central_transcripts['gene_source']+'\"; gene_biotype \"'+rna_central_transcripts['gene_biotype']+'\"; transcript_source \"'+rna_central_transcripts['gene_source']+'\"; transcript_biotype \"'+rna_central_transcripts['gene_biotype']+'\"; tag \"'+rna_central_transcripts['gene_source']+'\";'\n",
    "    rna_central_transcripts['order']=2\n",
    "    rna_central_transcripts = rna_central_transcripts[list(range(0,9))+['gene_id','order']]\n",
    "\n",
    "    rna_central_genes = rna_central.loc[rna_central[2]=='transcript'].copy().reset_index(drop=True)\n",
    "    rna_central_genes[2] = 'gene'\n",
    "    rna_central_genes[8] = 'gene_id \"'+rna_central_genes['gene_id']+'\"; gene_source \"'+rna_central_genes['gene_source']+'\"; gene_biotype \"'+rna_central_genes['gene_biotype']+'\";'\n",
    "    rna_central_genes['order']=1\n",
    "    rna_central_genes = rna_central_genes[list(range(0,9))+['gene_id','order']]\n",
    "\n",
    "    rna_central_gtf = pd.concat([rna_central_genes,rna_central_transcripts,rna_central_exons]).sort_values(['gene_id','order']).reset_index(drop=True).drop(['gene_id','order'],1)\n",
    "\n",
    "    # save standard annotation enriched with RNA central\n",
    "    enriched_gtf = pd.concat([gtf_df,rna_central_gtf]).reset_index(drop=True)\n",
    "    genome_fai = pd.read_csv(file_paths[organism+'_genome_file']+'.fai',delimiter=\"\\t\",index_col=None,header=None)\n",
    "    enriched_gtf = pd.merge(genome_fai[[0]],enriched_gtf,how='inner',on=0)\n",
    "\n",
    "    # remove non-canonical chromosomes, they are not of interest\n",
    "    enriched_gtf = enriched_gtf.loc[enriched_gtf[0].str.startswith('chr')].reset_index(drop=True)\n",
    "    enriched_gtf.to_csv(file_paths[organism+'_enriched_annotation_file'], sep=str('\\t'),header=False,index=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec8577c-6b26-4d7b-a1ce-c4817c288e34",
   "metadata": {},
   "source": [
    "# Enrich ENCODE metadata using json files from ENCODE portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7df1c42-b5f1-48b5-80f3-21837c78fab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget -i /scicore/home/zavolan/GROUP/RBP_perturbational_networks/metadata/ENCODE_json_urls.txt -P /scicore/home/zavolan/GROUP/RBP_perturbational_networks/metadata/ENCODE_json_files/\n",
      "wget -i /scicore/home/zavolan/GROUP/RBP_perturbational_networks/metadata/ENCODE_fastq_json_urls.txt -P /scicore/home/zavolan/GROUP/RBP_perturbational_networks/metadata/ENCODE_fastq_json_files/\n"
     ]
    }
   ],
   "source": [
    "ENCODE_metadata = pd.read_csv(subdirs['metadata_dir']+'ENCODE_metadata.tsv',delimiter=\"\\t\",\n",
    "                                   index_col=None,header=0)\n",
    "\n",
    "# add information about where are right controls\n",
    "ENCODE_metadata['json_url'] = \"\"\"https://www.encodeproject.org\"\"\"+ENCODE_metadata['File dataset']+\"\"\"?format=json\"\"\"\n",
    "ENCODE_metadata[['json_url']].drop_duplicates().to_csv(subdirs['metadata_dir']+'ENCODE_json_urls.txt', sep=str('\\t'),header=False,index=None,quoting=csv.QUOTE_NONE)\n",
    "\n",
    "command = 'mkdir -p '+subdirs['metadata_dir']+'ENCODE_json_files/'\n",
    "out = subprocess.check_output(command, shell=True)\n",
    "\n",
    "command = \"\"\"wget -i \"\"\"+subdirs['metadata_dir']+'ENCODE_json_urls.txt -P '+subdirs['metadata_dir']+'ENCODE_json_files/'\n",
    "print(command)\n",
    "\n",
    "os.system(\"\"\"find \"\"\"+subdirs['metadata_dir']+'ENCODE_json_files/'+\"\"\" -name '*=json*' > \"\"\"+subdirs['temp_dir']+\"\"\"json_file_paths.tsv\"\"\")\n",
    "json_file_paths = pd.read_csv(subdirs['temp_dir']+'json_file_paths.tsv',delimiter=\"\\t\",\n",
    "                                   index_col=None,header=None)\n",
    "a = []\n",
    "for json_file_path in list(json_file_paths[0]):\n",
    "    json = pd.read_json(json_file_path,orient='index')\n",
    "    if len(json.loc['possible_controls'][0])>0:\n",
    "        a.append([json.loc['accession'][0],json.loc['possible_controls'][0][0]['accession']])\n",
    "    else:\n",
    "        a.append([json.loc['accession'][0],''])\n",
    "controls = pd.DataFrame(a,columns= ['File dataset','File dataset controls'])\n",
    "controls['File dataset'] = '/experiments/'+controls['File dataset']+'/'\n",
    "\n",
    "ENCODE_metadata = pd.merge(ENCODE_metadata,controls,how='left',on=['File dataset'])\n",
    "\n",
    "# add information about which file corresponds to read 1, and which - to read 2\n",
    "\n",
    "ENCODE_metadata['file_json_url'] = \"\"\"https://www.encodeproject.org/files/\"\"\"+ENCODE_metadata['File accession']+\"\"\"/?format=json\"\"\"\n",
    "ENCODE_metadata[['file_json_url']].drop_duplicates().to_csv(subdirs['metadata_dir']+'ENCODE_fastq_json_urls.txt', sep=str('\\t'),header=False,index=None,quoting=csv.QUOTE_NONE)\n",
    "\n",
    "command = 'mkdir -p '+subdirs['metadata_dir']+'ENCODE_fastq_json_files/'\n",
    "out = subprocess.check_output(command, shell=True)\n",
    "\n",
    "command = \"\"\"wget -i \"\"\"+subdirs['metadata_dir']+'ENCODE_fastq_json_urls.txt -P '+subdirs['metadata_dir']+'ENCODE_fastq_json_files/'\n",
    "print(command)\n",
    "\n",
    "os.system(\"\"\"find \"\"\"+subdirs['metadata_dir']+'ENCODE_fastq_json_files/'+\"\"\" -name '*=json*' > \"\"\"+subdirs['temp_dir']+\"\"\"json_fastq_file_paths.tsv\"\"\")\n",
    "json_fastq_file_paths = pd.read_csv(subdirs['temp_dir']+'json_fastq_file_paths.tsv',delimiter=\"\\t\",\n",
    "                                   index_col=None,header=None)\n",
    "\n",
    "a = []\n",
    "for json_file_path in list(json_fastq_file_paths[0]):\n",
    "    json = pd.read_json(json_file_path,orient='index')\n",
    "    a.append([json.loc['accession'][0],json.loc['paired_with'][0],json.loc['paired_end'][0],json.loc['biological_replicates_formatted'][0],json.loc['read_length'][0]])\n",
    "file_metadata = pd.DataFrame(a,columns= ['File accession','paired_with','paired_end','bioreplicate','read_length'])\n",
    "file_metadata['paired_with'] = file_metadata['paired_with'].str.replace('/files/','').str.replace('/','')\n",
    "\n",
    "ENCODE_metadata = pd.merge(ENCODE_metadata,file_metadata,how='left',on=['File accession'])\n",
    "\n",
    "def get_sample(x):\n",
    "    l = [x['File accession'],x['paired_with']]\n",
    "    l.sort()\n",
    "    return '_'.join(l)\n",
    "ENCODE_metadata['sample'] = ENCODE_metadata.apply(lambda x: get_sample(x),1)\n",
    "\n",
    "ENCODE_metadata['File dataset'] = ENCODE_metadata['File dataset'].str.replace('/experiments/','').str.replace('/','')\n",
    "\n",
    "EXPS = ENCODE_metadata.loc[~ENCODE_metadata['File target'].isna()].reset_index(drop=True)\n",
    "EXPS['experiment_id'] = EXPS['File dataset']+'_'+EXPS['File dataset controls']+';'+EXPS['Biosample term name']+';'+EXPS['File target']\n",
    "\n",
    "CONTROLS = ENCODE_metadata.loc[ENCODE_metadata['File target'].isna()].reset_index(drop=True)\n",
    "CONTROLS['File dataset controls'] = CONTROLS['File dataset']\n",
    "tmp = pd.merge(EXPS[['sample','experiment_id','Biosample term name','File target','File dataset controls']],CONTROLS[['File dataset controls','sample']],how='inner',on='File dataset controls')\n",
    "\n",
    "df = pd.melt(tmp,id_vars=['experiment_id','Biosample term name','File target'],value_vars=['sample_x','sample_y'],value_name='sample')[['sample','experiment_id','Biosample term name','File target']].drop_duplicates()\n",
    "\n",
    "# prepare the start samples table in which rows correspond to samples (like in SRA metadata) and experiment ids are provided\n",
    "encode_start_samples = pd.merge(df,ENCODE_metadata.loc[ENCODE_metadata['paired_end']=='1'][['sample','read_length','File target','bioreplicate','Assay term name','File download URL']].rename(columns={'File download URL':'fq1','File target':'EXP_CTL'}),how='left',on='sample')\n",
    "encode_start_samples = pd.merge(encode_start_samples,ENCODE_metadata.loc[ENCODE_metadata['paired_end']=='2'][['sample','File download URL']].rename(columns={'File download URL':'fq2'}),how='left',on='sample')\n",
    "\n",
    "encode_start_samples = encode_start_samples[['sample','fq1','fq2','read_length','bioreplicate','EXP_CTL','experiment_id','Biosample term name','File target','Assay term name']]\n",
    "encode_start_samples['experiment_id'] = encode_start_samples['experiment_id']+';'+(encode_start_samples['Assay term name'].str.contains('shRNA')).astype('str').str.replace('True','KD').replace('False','KO')\n",
    "encode_start_samples['EXP_CTL'] = (encode_start_samples['EXP_CTL'].isna()).astype('str').str.replace('True','CTL').replace('False','EXP')\n",
    "encode_start_samples = encode_start_samples.sort_values(['experiment_id','EXP_CTL']).reset_index(drop=True)\n",
    "encode_start_samples = encode_start_samples.rename(columns = {'File target':'targeted_gene','Biosample term name':'cell_line'})\n",
    "encode_start_samples['assay'] = (encode_start_samples['Assay term name'].str.contains('shRNA')).astype('str').str.replace('True','shRNA').replace('False','CRISPR')\n",
    "\n",
    "encode_start_samples['genome_file'] = file_paths['human_genome_file']\n",
    "encode_start_samples['gtf_file'] = file_paths['human_enriched_annotation_file']\n",
    "encode_start_samples['organism'] = 'human'\n",
    "encode_start_samples = encode_start_samples[['sample','fq1','fq2','read_length','organism','genome_file','gtf_file','experiment_id','targeted_gene','bioreplicate','EXP_CTL','cell_line','assay']]\n",
    "\n",
    "encode_start_samples.to_csv(subdirs['metadata_dir']+'encode_start_samples.tsv', sep=str('\\t'),header=True,index=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a48ec430-38c0-4d0b-9fb7-37cc9ef466d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_start_samples.drop_duplicates('sample'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab60c347-2619-4648-adc9-e46c36561dd7",
   "metadata": {},
   "source": [
    "# Prepare .yaml config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8f136e6b-634c-4da4-a6b5-64df594fb796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load default rule_config, modify it and save\n",
    "\n",
    "WF_version = 'v1'\n",
    "\n",
    "yaml = ruamel.yaml.YAML()\n",
    "yaml.preserve_quotes = True\n",
    "with open(subdirs['wf_dir']+'config.yaml') as f_read:\n",
    "    data = yaml.load(f_read)\n",
    "data['samples_file'] = subdirs['metadata_dir']+'encode_start_samples.tsv'\n",
    "\n",
    "data['output_dir'] = subdirs['wf_runs_dir']+WF_version+'/output/'\n",
    "data['local_log'] = subdirs['wf_runs_dir']+WF_version+'/output/local_log/'\n",
    "data['cluster_log'] = subdirs['wf_runs_dir']+WF_version+'/output/cluster_log/'\n",
    "\n",
    "command = 'mkdir -p '+subdirs['wf_runs_dir']+WF_version+'/output/'\n",
    "out = subprocess.check_output(command, shell=True)\n",
    "\n",
    "with open(subdirs['wf_runs_dir']+WF_version+'/config.yaml','w') as f_write:     \n",
    "    yaml.dump(data, f_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c64876a-71f7-4414-a7e0-19c1888ea0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scicore/home/zavolan/GROUP/RBP_perturbational_networks/wf_runs/v1/output/cluster_log/'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdirs['wf_runs_dir']+WF_version+'/output/cluster_log/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503e062-3f22-47f5-826b-adc0f0f062fe",
   "metadata": {},
   "source": [
    "# Run main WF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21562599-9b2d-488d-812d-637bc7438dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scicore/home/zavolan/mirono0000/Projects/RBP_perturbational_networks/WF/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdirs['wf_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6baeae43-e94c-4dee-a5c2-57c645d19787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snakemake --snakefile Snakefile --configfile /scicore/home/zavolan/GROUP/RBP_perturbational_networks/wf_runs/v1/config.yaml --printshellcmds --use-conda --conda-frontend conda --use-singularity --singularity-args \"--bind /scicore/home/zavolan/GROUP/RBP_perturbational_networks/,/scicore/home/zavolan/GROUP/Genomes/homo_sapiens/\" --cluster-config cluster.json --cores 500 --local-cores 10 --jobs 100 --latency-wait 60 --cluster \"sbatch --cpus-per-task={cluster.threads} --mem={cluster.mem} --qos={cluster.queue} --partition={cluster.partition} --time={cluster.time} --output={cluster.out}\" --nolock -np'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WF_version = 'v1'\n",
    "\n",
    "command = \"\"\"snakemake \\\n",
    "--snakefile Snakefile \\\n",
    "--configfile \"\"\"+subdirs['wf_runs_dir']+WF_version+'/config.yaml'+\"\"\" \\\n",
    "--printshellcmds \\\n",
    "--use-conda --conda-frontend conda \\\n",
    "--use-singularity \\\n",
    "--singularity-args \"--bind \"\"\"+subdirs['main_project_dir']+','+subdirs['human_annotation_dir']+\"\"\"\" \\\n",
    "--cluster-config cluster.json \\\n",
    "--cores 500 \\\n",
    "--local-cores 10 \\\n",
    "--jobs 100 \\\n",
    "--latency-wait 60 \\\n",
    "--cluster \"sbatch \\\n",
    "--cpus-per-task={cluster.threads} \\\n",
    "--mem={cluster.mem} \\\n",
    "--qos={cluster.queue} \\\n",
    "--partition={cluster.partition} \\\n",
    "--time={cluster.time} \\\n",
    "--output={cluster.out}\" \\\n",
    "--nolock \\\n",
    "-np\"\"\"\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cf6f4-3521-4ae7-87a5-ed14b0151182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57631bbb-e0de-45f3-a225-5d6ccf9ce3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015c2df-c257-4de2-bd0d-02ed563475ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ea1eff-a779-40e3-b345-e85ebce5218e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999113a0-623c-4eed-a0ab-0137a04ff7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5045c03-f742-4275-8312-afdf6b7ce7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=$(zcat /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/INTS11C_replicate10_exp5/map_genome/read_categories/2_um/INTS11C_replicate10_exp5.2_um.fastq.gz | head -n 2 | tail -n 1 | awk '{print length}')\n",
    "l=$((s<150 ? s : 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af85fe-eb01-4ba7-a291-9843bae85f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691a01a-6834-4a7d-a7a2-b2b0d98b7233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70177a5e-cbff-4710-a1c8-1eee5abca9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c76ca-c659-4827-bc66-a0e2bb118819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb144060-d302-4e73-82b2-3e223035ded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24325f6f-b7d8-4a86-97d0-ad4f82839549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'picard FilterSamReads I=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/SRR15070640.dedup.sorted.indexed.bam O=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/read_categories/5_um/picard_test.sam READ_LIST_FILE=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/read_categories/5_um/SRR15070640.5_um.read_names.txt FILTER=includeReadList'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"picard FilterSamReads I=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/SRR15070640.dedup.sorted.indexed.bam \\\n",
    "O=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/read_categories/5_um/picard_test.sam \\\n",
    "READ_LIST_FILE=/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/SRR15070640/map_genome/read_categories/5_um/SRR15070640.5_um.read_names.txt \\\n",
    "FILTER=includeReadList\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f072a4a-ee60-4bae-becb-5df38de27876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319671b-8c15-4ecf-a318-b43d6d972537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9edb97-8e83-46f0-bf78-f210f9b20881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python /scicore/home/zavolan/mirono0000/Projects/bCLIP/bclip_workflow/scripts/get_genome_segmentations.py --input_gtf /scicore/home/zavolan/GROUP/Genomes/mus_musculus/enriched.gencode.vM32.annotation.gtf --input_genome_fai /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/genome_indices/mouse/genome.fai --output_exon_intron_gs /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/exon_intron_genome_segmentation.bed --output_binned_gs /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/binned_genome_segmentation.bed --bin_size 10 --temp_dir /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/temp --output_modified_gtf /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/modified_annotation.gtf --gene_flank 1000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = \"\"\"python /scicore/home/zavolan/mirono0000/Projects/bCLIP/bclip_workflow/scripts/get_genome_segmentations.py \\\n",
    "--input_gtf /scicore/home/zavolan/GROUP/Genomes/mus_musculus/enriched.gencode.vM32.annotation.gtf \\\n",
    "--input_genome_fai /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/genome_indices/mouse/genome.fai \\\n",
    "--output_exon_intron_gs /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/exon_intron_genome_segmentation.bed \\\n",
    "--output_binned_gs /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/binned_genome_segmentation.bed \\\n",
    "--bin_size 10 \\\n",
    "--temp_dir /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/temp \\\n",
    "--output_modified_gtf /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/transcriptome/mouse/modified_annotation.gtf \\\n",
    "--gene_flank 1000\"\"\"\n",
    "command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00360129-3022-42b7-a320-cefa38462a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a14d3-8b44-493d-b576-e4c4ed09fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedtools bamtobed -split -cigar -i /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/NRDE2_replicate3_exp10/map_genome/NRDE2_replicate3_exp10.Aligned.sortedByCoord.out.bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ef854-5604-4e8f-9ffb-39f279506430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45447b-51ad-4f91-b306-f5f24956de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "set +o pipefail; bedtools bamtobed -cigar -i {input.bam} | bedtools groupby -g 4 -c 7 -o distinct | awk '$2 !~ /,/' | awk '$2 !~ /N/' | bedtools groupby -g 2 -c 2 -o count > {output.cigar_frequencies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51aefb7-d9ef-4aa0-9827-6b9170a673bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a964949d-93f6-4e77-984f-d93ee654041f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/RBC_replicate1/map_genome/read_categories/'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "grouped_bed_file_path = '/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/RBC_replicate1/map_genome/RBC_replicate1.dedup.sorted.indexed.grouped.bed'\n",
    "bed_file_path = '/scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/output/samples/RBC_replicate1/map_genome/RBC_replicate1.dedup.sorted.indexed.bed'\n",
    "\n",
    "outdir = os.path.dirname(grouped_bed_file_path)+'/read_categories/'\n",
    "sample_id = os.path.basename(grouped_bed_file_path).replace('.dedup.sorted.indexed.grouped.bed','')\n",
    "\n",
    "d_cats = [0,1,2,3,4,5]\n",
    "mm_modes = ['um','mm']\n",
    "\n",
    "read_categories = list(itertools.product(*[d_cats,mm_modes])) # cartesian product\n",
    "\n",
    "grouped_bed_file = pd.read_csv(grouped_bed_file_path,delimiter=\"\\t\",index_col=None,header=None)\n",
    "grouped_bed_file.columns = [0,1,2,'name','w',5,'d','wd','d_cat']\n",
    "\n",
    "for read_category in read_categories:\n",
    "    cat_name = '_'.join(list(pd.Series(read_category).astype('str')))\n",
    "    out_subdir = outdir+cat_name+'/'\n",
    "    command = 'mkdir -p '+out_subdir\n",
    "    out = subprocess.check_output(command, shell=True)    \n",
    "\n",
    "    output_read_names_path = out_subdir+sample_id+'.'+cat_name+'.read_names.txt'\n",
    "    output_read_weights_path = out_subdir+sample_id+'.'+cat_name+'.read_weights.txt'\n",
    "    \n",
    "    d_cat = read_category[0]\n",
    "    if read_category[1]=='um':\n",
    "        cur_reads = bed_file.loc[(bed_file['d_cat']==d_cat)&(bed_file['w']==1)]\n",
    "    else:\n",
    "        cur_reads = bed_file.loc[(bed_file['d_cat']==d_cat)&(bed_file['w']<1)]\n",
    "    if len(cur_reads)==0:\n",
    "        command = 'echo \"empty\" > '+output_read_names_path\n",
    "        out = subprocess.check_output(command, shell=True)\n",
    "        command = 'echo \"0\" > '+output_read_weights_path\n",
    "        out = subprocess.check_output(command, shell=True)\n",
    "        continue\n",
    "    cur_reads = cur_reads.sort_values([0,1,2])reset_index(drop=True)\n",
    "    cur_reads[[0,1,2,'name','w',5]].to_csv(out_subdir+'temp1.bed', sep=str('\\t'),header=True,index=None)\n",
    "    \n",
    "    command = 'bedtools intersect -a '+out_subdir+'temp1.bed -b '+bed_file_path+' -wo -f 1.0 -r -s | bedtools groupby -g <QNAME> -c <w> -o first > '+out_subdir+'temp2.bed'\n",
    "    out = subprocess.check_output(command, shell=True)\n",
    "    \n",
    "    command = 'cut -f1 '+out_subdir+'temp2.bed > '+output_read_names_path\n",
    "    out = subprocess.check_output(command, shell=True)\n",
    "    command = 'cut -f2 '+out_subdir+'temp2.bed > '+output_read_weights_path\n",
    "    out = subprocess.check_output(command, shell=True)\n",
    "\n",
    "    command = 'rm '+out_subdir+'temp2.bed '+out_subdir+'temp1.bed'\n",
    "    out = subprocess.check_output(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f139542-9bb7-4c07-9918-426a3b85f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'um'),\n",
       " (0, 'mm'),\n",
       " (1, 'um'),\n",
       " (1, 'mm'),\n",
       " (2, 'um'),\n",
       " (2, 'mm'),\n",
       " (3, 'um'),\n",
       " (3, 'mm'),\n",
       " (4, 'um'),\n",
       " (4, 'mm'),\n",
       " (5, 'um'),\n",
       " (5, 'mm')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980836c-93f7-4b8d-9afe-a4d1397c6558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e012fbe5-f676-4bd6-bc68-e9a184049643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97bc406b-dced-4589-8458-456e25cdfa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "sbatch /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/scripts/bracken_build.sbatch\n"
     ]
    }
   ],
   "source": [
    "# building bracken dbs for all lengths present\n",
    "kraken_db = '/scicore/home/zavolan/GROUP/Genomes/KRAKEN_DB/standard/'\n",
    "start_samples = pd.read_csv(subdirs['metadata_dir']+'start_samples.tsv',delimiter=\"\\t\",index_col=None,header=0)\n",
    "\n",
    "read_lengths_file_name = subdirs['temp_dir']+'read_lengths.tsv'\n",
    "read_lengths = pd.read_csv(subdirs['wf_output_dir']+'misc/max_read_lengths.tsv',delimiter=\"\\t\",index_col=None,header=0)\n",
    "read_lengths = read_lengths[['max_read_length_estimate']].drop_duplicates().rename(columns = {'max_read_length_estimate':'index_size'}).reset_index(drop=True)\n",
    "\n",
    "read_lengths['id'] = read_lengths.index+1\n",
    "read_lengths[['id','index_size']].to_csv(read_lengths_file_name, sep=str('\\t'),header=False,index=None)\n",
    "\n",
    "max_node_mem = 512\n",
    "mem = 400\n",
    "cpus = min(15,int(128/((max_node_mem*0.8)/mem)))\n",
    "print(str(cpus))\n",
    "\n",
    "f = open(subdirs['scripts_dir']+'bracken_build.sbatch', \"w\")\n",
    "\n",
    "preambula = \\\n",
    "\"\"\"#!/bin/bash\n",
    "  \n",
    "#SBATCH --job-name=bracken_build\n",
    "#SBATCH --time=5:00:00\n",
    "#SBATCH --qos=6hours\n",
    "#SBATCH --output=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.out\n",
    "#SBATCH --error=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.err\n",
    "#SBATCH --cpus-per-task=\"\"\"+str(cpus)+\"\"\"\n",
    "#SBATCH --mem=\"\"\"+str(mem)+\"\"\"G\n",
    "#SBATCH --array=1-\"\"\"+str(len(read_lengths))+\"\"\"%200\n",
    "\n",
    "source ~/.bashrc\n",
    "\"\"\"\n",
    "f.write(preambula)\n",
    "f.write(\"\"\"\n",
    "read_length=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $2} }' \"\"\"+read_lengths_file_name+\"\"\")\n",
    "echo $read_length\n",
    "\"\"\")\n",
    "\n",
    "command = \"\"\"bracken-build -d \"\"\"+kraken_db+\"\"\" -t \"\"\"+str(cpus)+\"\"\" -k 35 -l $read_length\"\"\"\n",
    "f.write(command)\n",
    "f.close()\n",
    "\n",
    "print('sbatch '+subdirs['scripts_dir']+'bracken_build.sbatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ff0a7c-bb18-4c0f-a4fa-93c874256dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "sbatch /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/scripts/kraken_unmapped_reads.sbatch\n"
     ]
    }
   ],
   "source": [
    "# do kraken and bracken for unmapped reads\n",
    "kraken_db = '/scicore/home/zavolan/GROUP/Genomes/KRAKEN_DB/standard/'\n",
    "\n",
    "start_samples = pd.read_csv(subdirs['metadata_dir']+'start_samples.tsv',delimiter=\"\\t\",index_col=None,header=0)\n",
    "# get length estimates for samples\n",
    "l = []\n",
    "for sample in list(start_samples['name']):\n",
    "    rl = pd.read_csv(subdirs['wf_output_dir']+'samples/'+sample+'/read_length/'+sample+'.max_read_length.txt',header=None).loc[0,0]\n",
    "    l.append(rl)\n",
    "start_samples['index_size'] = l\n",
    "start_samples = start_samples.rename(columns={'name':'sample'})\n",
    "\n",
    "sample_file_name = subdirs['temp_dir']+'unmapped_fastq_file_paths.tsv'\n",
    "\n",
    "os.system(\"\"\"find \"\"\"+subdirs['wf_output_dir']+\"\"\" -name '*.Unmapped.out.fastq.gz' > \"\"\"+sample_file_name)\n",
    "fastq_file_paths = pd.read_csv(sample_file_name,delimiter=\"\\t\",\n",
    "                                   index_col=None,header=None)\n",
    "fastq_file_paths.columns = ['path']\n",
    "fastq_file_paths['output_dir'] = fastq_file_paths['path'].str.split('map_genome/',expand=True)[0]+'kraken/'\n",
    "fastq_file_paths['sample'] = fastq_file_paths['path'].str.split('map_genome/',expand=True)[1].str.replace('.Unmapped.out.fastq.gz','')\n",
    "fastq_file_paths = pd.merge(fastq_file_paths,start_samples[['sample','index_size']].rename(columns={'index_size':'expected_read_length'}),how='inner',on='sample')\n",
    "fastq_file_paths['kraken_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.unmapped.kraken'\n",
    "fastq_file_paths['kreport_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.unmapped.kreport'\n",
    "fastq_file_paths['bracken_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.unmapped.bracken'\n",
    "fastq_file_paths['id'] = fastq_file_paths.index+1\n",
    "fastq_file_paths[['id','path','output_dir','kraken_output_file','kreport_output_file','bracken_output_file','expected_read_length']].to_csv(sample_file_name, sep=str('\\t'),header=False,index=None)\n",
    "\n",
    "max_node_mem = 512\n",
    "mem = 100\n",
    "cpus = int(128/((max_node_mem*0.8)/mem))\n",
    "print(str(cpus))\n",
    "\n",
    "f = open(subdirs['scripts_dir']+'kraken_unmapped_reads.sbatch', \"w\")\n",
    "\n",
    "preambula = \\\n",
    "\"\"\"#!/bin/bash\n",
    "  \n",
    "#SBATCH --job-name=kraken_unmapped_reads\n",
    "#SBATCH --time=1:00:00\n",
    "#SBATCH --qos=6hours\n",
    "#SBATCH --output=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.out\n",
    "#SBATCH --error=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.err\n",
    "#SBATCH --cpus-per-task=\"\"\"+str(cpus)+\"\"\"\n",
    "#SBATCH --mem=\"\"\"+str(mem)+\"\"\"G\n",
    "#SBATCH --array=1-\"\"\"+str(len(fastq_file_paths))+\"\"\"%200\n",
    "\n",
    "source ~/.bashrc\n",
    "\"\"\"\n",
    "f.write(preambula)\n",
    "f.write(\"\"\"\n",
    "fastq_file_path=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $2} }' \"\"\"+sample_file_name+\"\"\")\n",
    "output_dir=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $3} }' \"\"\"+sample_file_name+\"\"\")\n",
    "kraken_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $4} }' \"\"\"+sample_file_name+\"\"\")\n",
    "kreport_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $5} }' \"\"\"+sample_file_name+\"\"\")\n",
    "bracken_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $6} }' \"\"\"+sample_file_name+\"\"\")\n",
    "expected_read_length=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $7} }' \"\"\"+sample_file_name+\"\"\")\n",
    "echo $fastq_file_path\n",
    "echo $output_dir\n",
    "\"\"\")\n",
    "\n",
    "command = \"\"\"mkdir -p $output_dir\"\"\"\n",
    "f.write(command+'\\n') \n",
    "\n",
    "command = \"\"\"\n",
    "kraken2 \\\n",
    "--threads \"\"\"+str(cpus)+\"\"\" \\\n",
    "--db \"\"\"+kraken_db+\"\"\" \\\n",
    "--report $kreport_output_file \\\n",
    "$fastq_file_path > \\\n",
    "$kraken_output_file\"\"\"\n",
    "f.write(command)\n",
    "\n",
    "command = \"\"\" && bracken \\\n",
    "-d \"\"\"+kraken_db+\"\"\" \\\n",
    "-i $kreport_output_file \\\n",
    "-o $bracken_output_file \\\n",
    "-r $expected_read_length -l S -t 1\n",
    "\"\"\"\n",
    "f.write(command)\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('sbatch '+subdirs['scripts_dir']+'kraken_unmapped_reads.sbatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db9f54cf-96df-4174-8241-4cc20bb5b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "sbatch /scicore/home/zavolan/GROUP/StefanieCLIP/aleksei/scripts/kraken_mapped_reads.sbatch\n"
     ]
    }
   ],
   "source": [
    "# do kraken and bracken for mapped reads\n",
    "kraken_db = '/scicore/home/zavolan/GROUP/Genomes/KRAKEN_DB/standard/'\n",
    "\n",
    "start_samples = pd.read_csv(subdirs['metadata_dir']+'start_samples.tsv',delimiter=\"\\t\",index_col=None,header=0)\n",
    "# get length estimates for samples\n",
    "l = []\n",
    "for sample in list(start_samples['name']):\n",
    "    rl = pd.read_csv(subdirs['wf_output_dir']+'samples/'+sample+'/read_length/'+sample+'.max_read_length.txt',header=None).loc[0,0]\n",
    "    l.append(rl)\n",
    "start_samples['index_size'] = l\n",
    "start_samples = start_samples.rename(columns={'name':'sample'})\n",
    "\n",
    "sample_file_name = subdirs['temp_dir']+'mapped_fastq_file_paths.tsv'\n",
    "\n",
    "os.system(\"\"\"find \"\"\"+subdirs['wf_output_dir']+\"\"\" -name '*.Aligned.sortedByCoord.out.fastq.gz' > \"\"\"+sample_file_name)\n",
    "fastq_file_paths = pd.read_csv(sample_file_name,delimiter=\"\\t\",\n",
    "                                   index_col=None,header=None)\n",
    "fastq_file_paths.columns = ['path']\n",
    "fastq_file_paths['output_dir'] = fastq_file_paths['path'].str.split('map_genome/',expand=True)[0]+'kraken/'\n",
    "fastq_file_paths['sample'] = fastq_file_paths['path'].str.split('map_genome/',expand=True)[1].str.replace('.Aligned.sortedByCoord.out.fastq.gz','')\n",
    "fastq_file_paths = pd.merge(fastq_file_paths,start_samples[['sample','index_size']].rename(columns={'index_size':'expected_read_length'}),how='inner',on='sample')\n",
    "fastq_file_paths['kraken_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.mapped.kraken'\n",
    "fastq_file_paths['kreport_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.mapped.kreport'\n",
    "fastq_file_paths['bracken_output_file'] = fastq_file_paths['output_dir']+fastq_file_paths['sample']+'.mapped.bracken'\n",
    "fastq_file_paths['id'] = fastq_file_paths.index+1\n",
    "fastq_file_paths[['id','path','output_dir','kraken_output_file','kreport_output_file','bracken_output_file','expected_read_length']].to_csv(sample_file_name, sep=str('\\t'),header=False,index=None)\n",
    "\n",
    "max_node_mem = 512\n",
    "mem = 100\n",
    "cpus = int(128/((max_node_mem*0.8)/mem))\n",
    "print(str(cpus))\n",
    "\n",
    "f = open(subdirs['scripts_dir']+'kraken_mapped_reads.sbatch', \"w\")\n",
    "\n",
    "preambula = \\\n",
    "\"\"\"#!/bin/bash\n",
    "  \n",
    "#SBATCH --job-name=kraken_mapped_reads\n",
    "#SBATCH --time=1:00:00\n",
    "#SBATCH --qos=6hours\n",
    "#SBATCH --output=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.out\n",
    "#SBATCH --error=\"\"\"+subdirs['slurm_dir']+\"\"\"%A_%a.err\n",
    "#SBATCH --cpus-per-task=\"\"\"+str(cpus)+\"\"\"\n",
    "#SBATCH --mem=\"\"\"+str(mem)+\"\"\"G\n",
    "#SBATCH --array=1-\"\"\"+str(len(fastq_file_paths))+\"\"\"%200\n",
    "\n",
    "source ~/.bashrc\n",
    "\"\"\"\n",
    "f.write(preambula)\n",
    "f.write(\"\"\"\n",
    "fastq_file_path=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $2} }' \"\"\"+sample_file_name+\"\"\")\n",
    "output_dir=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $3} }' \"\"\"+sample_file_name+\"\"\")\n",
    "kraken_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $4} }' \"\"\"+sample_file_name+\"\"\")\n",
    "kreport_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $5} }' \"\"\"+sample_file_name+\"\"\")\n",
    "bracken_output_file=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $6} }' \"\"\"+sample_file_name+\"\"\")\n",
    "expected_read_length=$(awk -v i=$SLURM_ARRAY_TASK_ID '{ if ($1 == i) { print $7} }' \"\"\"+sample_file_name+\"\"\")\n",
    "echo $fastq_file_path\n",
    "echo $output_dir\n",
    "\"\"\")\n",
    "\n",
    "command = \"\"\"mkdir -p $output_dir\"\"\"\n",
    "f.write(command+'\\n') \n",
    "\n",
    "command = \"\"\"\n",
    "kraken2 \\\n",
    "--threads \"\"\"+str(cpus)+\"\"\" \\\n",
    "--db \"\"\"+kraken_db+\"\"\" \\\n",
    "--report $kreport_output_file \\\n",
    "$fastq_file_path > \\\n",
    "$kraken_output_file\"\"\"\n",
    "f.write(command)\n",
    "\n",
    "command = \"\"\" && bracken \\\n",
    "-d \"\"\"+kraken_db+\"\"\" \\\n",
    "-i $kreport_output_file \\\n",
    "-o $bracken_output_file \\\n",
    "-r $expected_read_length -l S -t 1\n",
    "\"\"\"\n",
    "f.write(command)\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('sbatch '+subdirs['scripts_dir']+'kraken_mapped_reads.sbatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ccd2daa-e7f6-4cc7-b353-4da22fb2099e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-py310]",
   "language": "python",
   "name": "conda-env-miniconda3-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
